####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
bison_raw <- read.csv("../data/YNP_bison_population_size.csv", row.names = 1)
bison_dat <- bison_raw[,2:ncol(bison_raw)]
bison_dat$count.mean <- round(bison_dat$count.mean)
# clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
# bison_climate_dat <- merge(bison_dat, clim_dat)
####
####  Fit forecasting GLM
####
my_model <- list(obs="count.mean", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_norm(model=my_model, data=bison_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
##  R script to fit a simple GLM for sagebrush percent cover,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze et al. (forthcoming)
##
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
##
rm(list=ls(all.names = TRUE))
####
####  Load libraries
####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
bison_raw <- read.csv("../data/YNP_bison_population_size.csv", row.names = 1)
bison_dat <- bison_raw[,2:ncol(bison_raw)]
bison_dat$count.mean <- round(bison_dat$count.mean)
# clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
# bison_climate_dat <- merge(bison_dat, clim_dat)
####
####  Fit forecasting GLM
####
my_model <- list(obs="count.mean", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_norm(model=my_model, data=bison_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
prediction_df
##  R script to fit a simple GLM for sagebrush percent cover,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze et al. (forthcoming)
##
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
##
rm(list=ls(all.names = TRUE))
####
####  Load libraries
####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
bison_raw <- read.csv("../data/YNP_bison_population_size.csv", row.names = 1)
bison_dat <- bison_raw[,2:ncol(bison_raw)]
bison_dat$count.mean <- round(bison_dat$count.mean)
# clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
# bison_climate_dat <- merge(bison_dat, clim_dat)
####
####  Fit forecasting GLM
####
my_model <- list(obs="count.mean", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_pois(model=my_model, data=bison_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
source('~/Repos/ecocast_compare/code/sagebrush_forecast.R', echo=TRUE)
##  R script to fit a simple GLM for sagebrush percent cover,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze et al. (forthcoming)
##
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
##
rm(list=ls(all.names = TRUE))
####
####  Load libraries
####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
sage_raw <- read.csv("../data/ARTR_quadratCover.csv")
sage_raw$year <- sage_raw$year+1900 # makes a calendar year
sage_dat <- ddply(sage_raw, .(year), summarise,
tot_cover = round(mean(totCover)/100)) # converts to percent cover, integer
clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
sage_climate_dat <- merge(sage_dat, clim_dat)
####
####  Fit forecasting GLM
####
fixed="~ppt1+TmeanSpr1"
my_model <- list(obs="tot_cover", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_pois(model=my_model, data=sage_climate_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = sage_climate_dat$year,
observation = sage_climate_dat$tot_cover,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Cover of sagebrush (%)")+
xlab("Year")+
theme_few()
##  R script to fit a simple GLM for sagebrush percent cover,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze et al. (forthcoming)
##
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
##
rm(list=ls(all.names = TRUE))
####
####  Load libraries
####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
bison_raw <- read.csv("../data/YNP_bison_population_size.csv", row.names = 1)
bison_dat <- bison_raw[,2:ncol(bison_raw)]
bison_dat$count.mean <- round(bison_dat$count.mean)
# clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
# bison_climate_dat <- merge(bison_dat, clim_dat)
####
####  Fit forecasting GLM
####
my_model <- list(obs="count.mean", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_norm(model=my_model, data=bison_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
##  R script to fit a simple GLM for sagebrush percent cover,
##  forecast 10 new years, and partition the forecast variance.
##
##  Based on Dietze et al. (forthcoming)
##
##  Author:       Andrew Tredennick (atredenn@gmail.com)
##  Date created: October 19, 2016
##
rm(list=ls(all.names = TRUE))
####
####  Load libraries
####
library(ggplot2)
library(ggthemes)
library(reshape2)
library(plyr)
library(rjags)
library(coda)
library(devtools)
# install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
library(ecoforecastR)
####
####  Load data, aggregate to yearly values
####
bison_raw <- read.csv("../data/YNP_bison_population_size.csv", row.names = 1)
bison_dat <- bison_raw[,2:ncol(bison_raw)]
bison_dat$count.mean <- round(bison_dat$count.mean)
# clim_dat <- read.csv("../data/idaho_climate.csv")
## Merge observation and climate data
# bison_climate_dat <- merge(bison_dat, clim_dat)
####
####  Fit forecasting GLM
####
my_model <- list(obs="count.mean", fixed=NULL, random=NULL, n.iter=5000)
fitted_model <- fit_dlm_norm(model=my_model, data=bison_dat)
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
source('~/Repos/ecocast_compare/code/bison_forecast.R', echo=TRUE)
model=my_model
data=bison_dat
obs   = model$obs
fixed  = model$fixed
random = model$random
n.iter = ifelse(is.null(model$n.iter),5000,model$n.iter)
data = as.data.frame(data)
out.variables = c("x","tau_add","tau_obs","beta_IC")
## observation design matrix
if(is.null(obs)){
print("Observations not included in model. Please add the variable 'obs' to the model list")
} else {
if(length(grep("~",obs)) == 0){ ## no formula, assuming obs is just a variable
if(obs %in% names(data)){
OBS = data[,obs]
} else {
print(paste("Could not find",obs,"in the provided data frame"))
return(NULL)
}
} else {  ## obs is a formula
print("obs formulas not implemented yet")
return(NULL)
}
}
## process design matrix
if(is.null(fixed)){
Z = NULL
} else {
if(is.null(data)) print("formula provided but covariate data is absent:",fixed)
fixed = ifelse(length(grep("~",fixed)) == 0,paste("~",fixed),fixed)
fixed = sub("x*~","~",x=fixed)
options(na.action = na.pass)
Z = with(data,model.matrix(formula(fixed),na.action=na.pass))
#    Z = as.matrix(Z[,-which(colnames(Z)=="(Intercept)")])
if(sum(is.na(Z))>0){
print("WARNING: missing covariate data")
print(apply(is.na(Z),2,sum))
}
}
## alternatively might be able to get fixed and random effects simultaneously using
## lme4::lFormula(formula("x ~ FIXED + (1|FACTOR)"),na.action=na.pass)
## e.g. foo = lme4::lFormula(formula("x ~ PAR + (1+PAR|DOY)"),na.action = na.pass)
#### Define JAGS model
my.model = "
model{
#### Priors
x[1] ~ dnorm(x_ic,tau_ic)
#tau_tot ~ dgamma(a_tot,r_tot)
tau_obs ~ dgamma(a_obs,r_obs)
tau_add ~ dgamma(a_add,r_add)
#### Random Effects
#RANDOM  tau_alpha~dgamma(0.1,0.1)
#RANDOM  for(i in 1:nrep){
#RANDOM   alpha[i]~dnorm(0,tau_alpha)
#RANDOM  }
#### Fixed Effects
beta_IC~dnorm(0,0.001)
##BETAs
##MISSING_MU
#### Data Model
for(t in 1:n){
OBS[t] ~ dlnorm(x[t], tau_obs)
##MISSING
}
#### Process Model
for(t in 2:n){
mu[t] <- beta_IC*x[t-1] ##PROCESS
x[t] ~ dnorm(mu[t], tau_add)
}
}"
#### prep data
mydat<-list(OBS=OBS,n=length(OBS),x_ic = 0,tau_ic = 0.00001, a_add=0.1,r_add=0.1,a_obs=0.1,r_obs=0.1)
#### prep model
## FIXED EFFECTS
Pformula = NULL
if(!is.null(Z)){
Pnames = gsub(" ","_",colnames(Z))
Pnames = gsub("(","",Pnames,fixed=TRUE)
Pnames = gsub(")","",Pnames,fixed=TRUE)
Pformula = paste(Pformula,paste0("+ beta",Pnames,"*Z[t,",1:ncol(Z),"]",collapse=" "))
Ppriors = paste0("beta",Pnames,"~dnorm(0,0.001)",collapse="\n")
my.model = sub(pattern="##BETAs",Ppriors,my.model)
mydat[["Z"]] = Z
out.variables = c(out.variables,paste0("beta",Pnames))
## missing data model
MDprior <- paste(
paste0("mu",Pnames,"~dnorm(0,0.001)",collapse="\n"),
paste0("tau",Pnames,"~dgamma(0.01,0.01)",collapse="\n")
)
my.model <- sub(pattern="##MISSING_MU",MDprior,my.model)
MDformula <- paste0("Z[t,",1:ncol(Z),"] ~ dnorm(mu",Pnames,",tau",Pnames,")",collapse="\n")
my.model <- sub(pattern="##MISSING",MDformula,my.model)
}
## RANDOM EFFECTS
if(!is.null(random)){
my.model = gsub(pattern="#RANDOM"," ",my.model)
out.variables = c(out.variables,"tau_alpha","alpha")
Pformula = " + alpha[rep[i]]"
## *****
## *****
}
if(!is.null(Pformula)) my.model = sub(pattern="##PROCESS",Pformula,my.model)
## Define initial conditions
## initialize model
mc3 <- jags.model(file=textConnection(my.model),data=mydat,
#inits=init,
n.chains=3)
mc3.out <- coda.samples(model=mc3, variable.names=out.variables, n.iter=n.iter)
## split output
out = list(params=NULL,predict=NULL,model=my.model,data=mydat)
mfit = as.matrix(mc3.out,chains=TRUE)
pred.cols = union(grep("x[",colnames(mfit),fixed=TRUE),grep("mu[",colnames(mfit),fixed=TRUE))
chain.col = which(colnames(mfit)=="CHAIN")
out$predict = mat2mcmc.list(mfit[,c(chain.col,pred.cols)])
out$params   = mat2mcmc.list(mfit[,-pred.cols])
fitted_model=out
predictions <- rbind(fitted_model$predict[[1]],
fitted_model$predict[[2]],
fitted_model$predict[[3]])
median_predictions <- apply(predictions, MARGIN = 2, FUN = "median")
upper_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.975)})
lower_predictions <- apply(predictions, MARGIN = 2, FUN = function(x){quantile(x, probs = 0.025)})
prediction_df <- data.frame(year = bison_dat$year,
observation = bison_dat$count.mean,
median_prediction = median_predictions,
upper_prediction = upper_predictions,
lower_prediction = lower_predictions)
####
####  Plot the calibration data and predictions
####
pred_color <- "dodgerblue"
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=median_prediction), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=upper_prediction, ymin=lower_prediction), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=exp(median_prediction)), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
ggplot(prediction_df, aes(x=year))+
geom_ribbon(aes(ymax=exp(upper_prediction), ymin=exp(lower_prediction)), fill=pred_color, color=NA, alpha=0.2)+
geom_line(aes(y=exp(median_prediction)), color=pred_color)+
geom_point(aes(y=observation))+
ylab("Number of bison")+
xlab("Year")+
theme_few()
setwd("~/Repos/ecoforecastR/R")
devtools::document()
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
setwd("~/Repos/ecoforecastR/R")
devtools::document()
setwd("~/Repos/ecocast_compare/code")
install_github("atredennick/ecoforecastR", force=TRUE) # get latest version
source('~/Repos/ecocast_compare/code/bison_forecast.R', echo=TRUE)
install.packages("rnoaa")
gefs_variables()
library(rnoaa)
gefs_variables()
install.packages("ncdf4")
library(rnoaa)
library(ncdf4)
gefs_variables()
lat <- 44.4280
lon <- 110.5885
gefs_variables()
snow_depth = gefs("Snow_depth_surface_ens",lat,lon,raw=TRUE)
